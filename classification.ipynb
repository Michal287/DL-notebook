{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Michal287/DL-notebook/blob/main/classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrNdI0PCDmTg"
      },
      "source": [
        "# Library instalations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNbwyIMkDskc"
      },
      "source": [
        "# Importowanie bibliotek"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0NvuVD5ZD5cE"
      },
      "outputs": [],
      "source": [
        "#os\n",
        "from imutils import paths\n",
        "import os\n",
        "from datetime import datetime\n",
        "from google.colab import drive\n",
        "\n",
        "#tools\n",
        "import numpy as np\n",
        "import pickle\n",
        "import random\n",
        "import imutils\n",
        "\n",
        "#sklearn\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#tensorflow tools\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "#tensorboard\n",
        "%load_ext tensorboard\n",
        "\n",
        "#tensorflow architecture\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Flatten\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "\n",
        "#cv2\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "#plots\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#agumentation\n",
        "import albumentations as A"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaaDWw1Rljms"
      },
      "source": [
        "# Remove logs in previous runs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u1gBmkI8ljDN"
      },
      "outputs": [],
      "source": [
        "!rm -rf ./logs/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23HNDhP8D816"
      },
      "source": [
        "# Connect to google drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w7J7va3KEAYl"
      },
      "outputs": [],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnVD8g07EsM0"
      },
      "source": [
        "# Checking GPU\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rY-yqQqE04d",
        "outputId": "d1859d8c-d4df-4c4a-d6ed-4cbde0df5668"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "for gpu in gpus:\n",
        "    tf.config.experimental.set_memory_growth(gpu, True)\n",
        "\n",
        "tf.config.list_physical_devices('GPU')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1RyqR12EK_-"
      },
      "source": [
        "# Download images from google drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YcwH-_5_EPZ9"
      },
      "outputs": [],
      "source": [
        "if not os.path.isdir('data'):\n",
        "  os.mkdir('data')\n",
        "\n",
        "if not os.path.isdir('output'):\n",
        "  os.mkdir('output')\n",
        "\n",
        "!unzip -q /content/drive/MyDrive/raw.zip -d /content/data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PocW0YYAhJ7"
      },
      "source": [
        "# Settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lIfyGukrAkcP"
      },
      "outputs": [],
      "source": [
        "image_width, image_height = 244, 244\n",
        "BATCH_SIZE = 8\n",
        "EPOCHS = 30"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKyUFWNdyKb9"
      },
      "source": [
        "# Agumentation Examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-HgQby8xyP5W"
      },
      "outputs": [],
      "source": [
        "transform = A.Compose([\n",
        "    #A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=1),\n",
        "    #A.HueSaturationValue(val_shift_limit=(-30, 30), p=1),\n",
        "    #A.Blur(blur_limit=2, p=.2),\n",
        "    #A.Rotate(limit=15, p=.2),\n",
        "    A.RandomCrop(210, 210),\n",
        "    A.Resize(width=image_width, height=image_height,p=1)\n",
        "])\n",
        "\n",
        "image = cv2.imread('data/raw_2/2/image_10.jpg')\n",
        "image = cv2.resize(image, (image_width, image_height))\n",
        "image_aug = transform(image=image)[\"image\"]\n",
        "cv2_imshow(image_aug)\n",
        "print(image_aug.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kzy8Qy-HBMgU"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dIT_W-8k_DNW"
      },
      "outputs": [],
      "source": [
        "transform = A.Compose([\n",
        "    A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=.8),\n",
        "    A.HueSaturationValue(p=.5),\n",
        "    A.Blur(blur_limit=3, p=.3),\n",
        "    A.Rotate(limit=15, p=.5)\n",
        "])\n",
        "\n",
        "def image_darkening(image):\n",
        "  #matrix = np.ones(image_crop.shape, dtype=\"float32\") * 255\n",
        "  #return cv2.subtract(image_crop, matrix)\n",
        "  image[:, :] = 0\n",
        "  return image\n",
        "\n",
        "def join_images(images):\n",
        "  return np.hstack( (np.asarray( image ) for image in images ) )\n",
        "\n",
        "def split_images(image, image_width, splitter=0.5):\n",
        "  width_crop = image_width - int(image_width*splitter)\n",
        "  return image[:,width_crop:], image[:, :width_crop] \n",
        "\n",
        "\n",
        "#Get all files in dictionary\n",
        "image_paths = list(paths.list_images('data/raw_2'))\n",
        "#Shuffle data\n",
        "np.random.shuffle(image_paths)\n",
        "\n",
        "data = []\n",
        "labels = []\n",
        "\n",
        "for image_path in image_paths:\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.resize(image, (image_width, image_height))\n",
        "    image_aug = transform(image=image)[\"image\"]\n",
        "    image_aug = img_to_array(image_aug)\n",
        "    image_aug2 = transform(image=image)[\"image\"]\n",
        "    image_aug2 = img_to_array(image_aug)\n",
        "    image = img_to_array(image)\n",
        "\n",
        "    width_crop = image_width - int(image_width*0.5)\n",
        "    image[:,width_crop:] = 0\n",
        "    image[:,:int(image_width*0.1)] = 0\n",
        "\n",
        "    width_crop = image_width - int(image_width*0.5)\n",
        "    image_aug[:,width_crop:] = 0\n",
        "    image_aug[:,:int(image_width*0.1)] = 0\n",
        "    \n",
        "    data.append(image)\n",
        "    data.append(image_aug)\n",
        "\n",
        "    label = image_path.split('/')[-2].split('_')\n",
        "    labels.append(label)\n",
        "    labels.append(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "TGQXKzNaIxDc"
      },
      "outputs": [],
      "source": [
        "for i in data[:100]:\n",
        "  cv2_imshow(i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suEszafQEmkO"
      },
      "source": [
        "# Normalize data and convert to numpy array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "f86wms7UCuWP"
      },
      "outputs": [],
      "source": [
        "data = np.array(data, dtype='float') / 255.\n",
        "labels = np.array(labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZiMtx0vFK8O"
      },
      "source": [
        "# Checking Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPBHp3noFLVF",
        "outputId": "1e59c11a-9696-4d27-c14e-2c00c1814ef6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] 336 obrazów o rozmiarze: 1406.54 MB\n",
            "[INFO] Kształt danych: (1008, 244, 244, 3)\n"
          ]
        }
      ],
      "source": [
        "print(f'[INFO] {len(image_paths)} obrazów o rozmiarze: {data.nbytes / (1024 * 1000.0):.2f} MB')\n",
        "print(f'[INFO] Kształt danych: {data.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LzV2wxgFXg0"
      },
      "source": [
        "# Checking labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "LaC7uWqdCx4F",
        "outputId": "cb95d27b-19f2-4e03-b780-e54d266889f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Etykiety: ['1' '2' '3']\n"
          ]
        }
      ],
      "source": [
        "mlb = MultiLabelBinarizer()\n",
        "labels = mlb.fit_transform(labels)\n",
        "print(f'[INFO] Etykiety: {mlb.classes_}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BM6YK6t5F0nS"
      },
      "source": [
        "# Save labels to file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFoKpc8KF2o8",
        "outputId": "07be3b5f-7941-4f05-dac0-1c50509cd31f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Eksport etykiet do pliku...\n"
          ]
        }
      ],
      "source": [
        "print('[INFO] Eksport etykiet do pliku...')\n",
        "with open(r'output/mlb.pickle', 'bw') as file:\n",
        "    pickle.dump(mlb, file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sL61qaA4GnbK"
      },
      "source": [
        "# Split data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9q9P7XfGiFz",
        "outputId": "45555188-856b-459a-c9ab-1bd2210b30d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Rozmiar danych treningowych: (756, 244, 244, 3)\n",
            "[INFO] Rozmiar danych testowych: (252, 244, 244, 3)\n"
          ]
        }
      ],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.3, random_state=10)\n",
        "\n",
        "print(f'[INFO] Rozmiar danych treningowych: {X_train.shape}')\n",
        "print(f'[INFO] Rozmiar danych testowych: {X_test.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Ows9VMRfImXE"
      },
      "outputs": [],
      "source": [
        "cv2_imshow(X_train[3]*255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "V399foRwrzCj"
      },
      "outputs": [],
      "source": [
        "def target_repair(lab):\n",
        "  target = []\n",
        "\n",
        "  for i in lab:\n",
        "    target.append(np.argmax(i))\n",
        "\n",
        "  return target\n",
        "\n",
        "y_train, y_test = target_repair(y_train), target_repair(y_test)\n",
        "y_train, y_test = to_categorical(y_train, 3), to_categorical(y_test, 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xh9YpZF6RdD7"
      },
      "source": [
        "# Create Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZ4RHMPjGiMg",
        "outputId": "11a5b106-60cf-4a0c-e93c-9bba5320ea88",
        "collapsed": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_6 (Conv2D)           (None, 244, 244, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 122, 122, 32)     0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 122, 122, 64)      18496     \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPooling  (None, 61, 61, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 61, 61, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPooling  (None, 30, 30, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 115200)            0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 128)               14745728  \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 32)                4128      \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 3)                 99        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,843,203\n",
            "Trainable params: 14,843,203\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = Sequential([\n",
        "        Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same', input_shape=(244, 244, 3)),\n",
        "        MaxPool2D(pool_size=(2, 2)),\n",
        "        \n",
        "        Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'),\n",
        "        MaxPool2D(pool_size=(2, 2)),\n",
        "        \n",
        "        Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'),\n",
        "        MaxPool2D(pool_size=(2, 2)),\n",
        "        \n",
        "        Flatten(),\n",
        "\n",
        "        Dense(128, activation='relu'),\n",
        "        Dense(3, activation='softmax')\n",
        "    ])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdrzlBfKSrb2"
      },
      "source": [
        "# Creating best checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3qL6JDVzGiPa"
      },
      "outputs": [],
      "source": [
        "dt = datetime.now().strftime('%d_%m_%Y_%H_%M')\n",
        "filepath = os.path.join('output', 'model_' + dt + '.hdf5')\n",
        "checkpoint = ModelCheckpoint(filepath=filepath, monitor='val_accuracy', save_best_only=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2odqW2QPmNC6"
      },
      "source": [
        "# Connect to tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Sj1qqsQmQBR"
      },
      "outputs": [],
      "source": [
        "log_dir = \"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_U-QY_cTJRo"
      },
      "source": [
        "# Trening model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ObQJSVe7GiRx",
        "outputId": "76a12085-0945-49f3-c205-3e51b6366af7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Trenowanie modelu...\n",
            "Epoch 1/30\n",
            "67/67 [==============================] - 7s 99ms/step - loss: 0.6854 - accuracy: 0.6996 - val_loss: 0.3717 - val_accuracy: 0.8370\n",
            "Epoch 2/30\n",
            "67/67 [==============================] - 5s 77ms/step - loss: 0.2683 - accuracy: 0.9017 - val_loss: 0.4212 - val_accuracy: 0.8296\n",
            "Epoch 3/30\n",
            "67/67 [==============================] - 4s 66ms/step - loss: 0.1206 - accuracy: 0.9641 - val_loss: 0.0992 - val_accuracy: 0.9630\n",
            "Epoch 4/30\n",
            "67/67 [==============================] - 4s 64ms/step - loss: 0.0479 - accuracy: 0.9887 - val_loss: 0.0567 - val_accuracy: 0.9852\n",
            "Epoch 5/30\n",
            "67/67 [==============================] - 4s 65ms/step - loss: 0.0479 - accuracy: 0.9868 - val_loss: 0.0287 - val_accuracy: 0.9926\n",
            "Epoch 6/30\n",
            "67/67 [==============================] - 4s 57ms/step - loss: 0.0517 - accuracy: 0.9849 - val_loss: 0.0613 - val_accuracy: 0.9630\n",
            "Epoch 7/30\n",
            "67/67 [==============================] - 4s 57ms/step - loss: 0.0057 - accuracy: 0.9981 - val_loss: 0.0673 - val_accuracy: 0.9778\n",
            "Epoch 8/30\n",
            "67/67 [==============================] - 4s 63ms/step - loss: 0.0089 - accuracy: 0.9962 - val_loss: 0.0303 - val_accuracy: 0.9926\n",
            "Epoch 9/30\n",
            "67/67 [==============================] - 4s 58ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0453 - val_accuracy: 0.9778\n",
            "Epoch 10/30\n",
            "67/67 [==============================] - 4s 57ms/step - loss: 0.0713 - accuracy: 0.9773 - val_loss: 0.0291 - val_accuracy: 0.9926\n",
            "Epoch 11/30\n",
            "67/67 [==============================] - 4s 60ms/step - loss: 0.1652 - accuracy: 0.9679 - val_loss: 1.3664 - val_accuracy: 0.8222\n",
            "Epoch 12/30\n",
            "67/67 [==============================] - 4s 59ms/step - loss: 0.0988 - accuracy: 0.9792 - val_loss: 0.0238 - val_accuracy: 0.9926\n",
            "Epoch 13/30\n",
            "67/67 [==============================] - 4s 56ms/step - loss: 0.0589 - accuracy: 0.9868 - val_loss: 0.0553 - val_accuracy: 0.9778\n",
            "Epoch 14/30\n",
            "67/67 [==============================] - 4s 57ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.0977 - val_accuracy: 0.9704\n",
            "Epoch 15/30\n",
            "67/67 [==============================] - 4s 57ms/step - loss: 9.7171e-04 - accuracy: 1.0000 - val_loss: 0.0173 - val_accuracy: 0.9926\n",
            "Epoch 16/30\n",
            "67/67 [==============================] - 4s 57ms/step - loss: 0.0582 - accuracy: 0.9830 - val_loss: 0.0255 - val_accuracy: 0.9926\n",
            "Epoch 17/30\n",
            "67/67 [==============================] - 4s 56ms/step - loss: 0.0110 - accuracy: 0.9962 - val_loss: 0.0406 - val_accuracy: 0.9926\n",
            "Epoch 18/30\n",
            "67/67 [==============================] - 4s 58ms/step - loss: 4.6469e-04 - accuracy: 1.0000 - val_loss: 0.0444 - val_accuracy: 0.9852\n",
            "Epoch 19/30\n",
            "67/67 [==============================] - 4s 60ms/step - loss: 2.3836e-04 - accuracy: 1.0000 - val_loss: 0.0419 - val_accuracy: 0.9852\n",
            "Epoch 20/30\n",
            "67/67 [==============================] - 4s 57ms/step - loss: 1.2929e-04 - accuracy: 1.0000 - val_loss: 0.0414 - val_accuracy: 0.9852\n",
            "Epoch 21/30\n",
            "67/67 [==============================] - 4s 56ms/step - loss: 1.1307e-04 - accuracy: 1.0000 - val_loss: 0.0428 - val_accuracy: 0.9852\n",
            "Epoch 22/30\n",
            "67/67 [==============================] - 4s 57ms/step - loss: 9.5020e-05 - accuracy: 1.0000 - val_loss: 0.0405 - val_accuracy: 0.9852\n",
            "Epoch 23/30\n",
            "67/67 [==============================] - 4s 57ms/step - loss: 9.4449e-05 - accuracy: 1.0000 - val_loss: 0.0383 - val_accuracy: 0.9852\n",
            "Epoch 24/30\n",
            "67/67 [==============================] - 4s 57ms/step - loss: 3.4663e-05 - accuracy: 1.0000 - val_loss: 0.0415 - val_accuracy: 0.9778\n",
            "Epoch 25/30\n",
            "67/67 [==============================] - 4s 59ms/step - loss: 4.3380e-05 - accuracy: 1.0000 - val_loss: 0.0399 - val_accuracy: 0.9778\n",
            "Epoch 26/30\n",
            "67/67 [==============================] - 4s 63ms/step - loss: 3.9071e-05 - accuracy: 1.0000 - val_loss: 0.0413 - val_accuracy: 0.9778\n",
            "Epoch 27/30\n",
            "67/67 [==============================] - 4s 56ms/step - loss: 2.7829e-05 - accuracy: 1.0000 - val_loss: 0.0441 - val_accuracy: 0.9778\n",
            "Epoch 28/30\n",
            "67/67 [==============================] - 4s 58ms/step - loss: 2.9315e-05 - accuracy: 1.0000 - val_loss: 0.0470 - val_accuracy: 0.9778\n",
            "Epoch 29/30\n",
            "67/67 [==============================] - 4s 57ms/step - loss: 1.0739e-05 - accuracy: 1.0000 - val_loss: 0.0472 - val_accuracy: 0.9778\n",
            "Epoch 30/30\n",
            "67/67 [==============================] - 4s 58ms/step - loss: 2.0589e-05 - accuracy: 1.0000 - val_loss: 0.0464 - val_accuracy: 0.9778\n"
          ]
        }
      ],
      "source": [
        "print(f'[INFO] Trenowanie modelu...')\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, \n",
        "    y_train, \n",
        "    batch_size=BATCH_SIZE,\n",
        "    validation_data=(X_test, y_test),\n",
        "    steps_per_epoch=len(X_train) // BATCH_SIZE,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=[checkpoint, tensorboard_callback]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BV1QssLhnwpW"
      },
      "source": [
        "# Run Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xqvIhqBRnvbA"
      },
      "outputs": [],
      "source": [
        "%tensorboard --logdir logs/fit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSbyTGChTcIy"
      },
      "source": [
        "# Creating charts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3NPdmPeGiUM",
        "outputId": "01700cf1-c91d-43b5-fa66-c01897d35104"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Eksport wykresu do pliku output/report_24_10_2022_07_32.html...\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.graph_objects as go\n",
        "import plotly.offline as po\n",
        "\n",
        "\n",
        "def plot_hist(history, filename):\n",
        "    hist = pd.DataFrame(history.history)\n",
        "    hist['epoch'] = history.epoch\n",
        "\n",
        "    fig = make_subplots(rows=2, cols=1, subplot_titles=('Accuracy', 'Loss'))\n",
        "\n",
        "    fig.add_trace(go.Scatter(x=hist['epoch'], y=hist['accuracy'], name='train_accuracy',\n",
        "                             mode='markers+lines', marker_color='#f29407'), row=1, col=1)\n",
        "    fig.add_trace(go.Scatter(x=hist['epoch'], y=hist['val_accuracy'], name='valid_accuracy',\n",
        "                             mode='markers+lines', marker_color='#0771f2'), row=1, col=1)\n",
        "    fig.add_trace(go.Scatter(x=hist['epoch'], y=hist['loss'], name='train_loss',\n",
        "                             mode='markers+lines', marker_color='#f29407'), row=2, col=1)\n",
        "    fig.add_trace(go.Scatter(x=hist['epoch'], y=hist['val_loss'], name='valid_loss',\n",
        "                             mode='markers+lines', marker_color='#0771f2'), row=2, col=1)\n",
        "\n",
        "    fig.update_xaxes(title_text='Liczba epok', row=1, col=1)\n",
        "    fig.update_xaxes(title_text='Liczba epok', row=2, col=1)\n",
        "    fig.update_yaxes(title_text='Accuracy', row=1, col=1)\n",
        "    fig.update_yaxes(title_text='Loss', row=2, col=1)\n",
        "    fig.update_layout(width=1400, height=1000, title=f\"Metrics\")\n",
        "\n",
        "    po.plot(fig, filename=filename, auto_open=False)\n",
        "\n",
        "\n",
        "\n",
        "filename = os.path.join('output', 'report_' + dt + '.html')\n",
        "print(f'[INFO] Eksport wykresu do pliku {filename}...')\n",
        "plot_hist(history, filename=filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3BkxhdyS7ib"
      },
      "source": [
        "# Load test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yd6gBupgS808"
      },
      "outputs": [],
      "source": [
        "if not os.path.isdir('test_data'):\n",
        "  os.mkdir('test_data')\n",
        "\n",
        "!unzip -q /content/drive/MyDrive/test_data.zip -d /content/test_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zVDc44CcBzi"
      },
      "source": [
        "# Load model and labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6KMEjL6j-j0",
        "outputId": "672d352b-67c7-4fc9-cc48-86d6c2313d31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Loading model...\n",
            "[INFO] Loading labels...\n"
          ]
        }
      ],
      "source": [
        "print('[INFO] Loading model...')\n",
        "model = load_model('output/model_'+dt+'.hdf5')\n",
        "\n",
        "print('[INFO] Loading labels...')\n",
        "with open(r'output/mlb.pickle', 'br') as file:\n",
        "    mlb = pickle.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "IToBgZ05b9pb"
      },
      "outputs": [],
      "source": [
        "#filename = 'test_data/test_3.jpg'\n",
        "filename = 'data/raw_2/3/image_143.jpg'\n",
        "\n",
        "def load(filename):\n",
        "    image = cv2.imread(filename)\n",
        "    image = cv2.resize(image, (244, 244))\n",
        "    image = image.astype('float') / 255.\n",
        "    image = img_to_array(image)\n",
        "    image = np.expand_dims(image, axis=0)\n",
        "    width_crop = image_width - int(image_width*0.6)\n",
        "    image[:,width_crop:] = 0\n",
        "\n",
        "    return image\n",
        "\n",
        "image = load(filename)\n",
        "\n",
        "y_pred = model.predict(image)[0]\n",
        "\n",
        "labels = dict(enumerate(mlb.classes_))\n",
        "print(labels)\n",
        "idxs = np.argsort(y_pred)\n",
        "\n",
        "print('[INFO] Loading image...')\n",
        "image = cv2.imread(filename)\n",
        "\n",
        "print('[INFO] Displaying image...')\n",
        "for i, idx in enumerate(idxs):\n",
        "    cv2.putText(img=image, text=f'Labels: {labels[idx]:6} Probability: {y_pred[idx] * 100:.4f}%',\n",
        "                org=(10, (i * 30) + 25), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=0.5,\n",
        "                color=(0, 0, 255), thickness=1)\n",
        "\n",
        "cv2_imshow(image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UW51NO-kGn8F"
      },
      "source": [
        "Checking important feautres"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vOfru4mwGrGM"
      },
      "outputs": [],
      "source": [
        "_img = cv2.imread('test_data/test_1.jpg')\n",
        "_img = cv2.resize(_img, (244, 244))\n",
        "cv2_imshow(_img)\n",
        "\n",
        "width_crop = image_width - int(image_width*0.6)\n",
        "_img[:,width_crop:] = 0\n",
        "cv2_imshow(_img)\n",
        "\n",
        "d = _img[44: ,44:]\n",
        "cv2_imshow(d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BWdT-2MFJika"
      },
      "outputs": [],
      "source": [
        "img = _img.astype('float') / 255.\n",
        "img = np.expand_dims(img, axis=0)\n",
        "\n",
        "images = tf.Variable(img, dtype=float)\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "    pred = model(images, training=False)\n",
        "    class_idxs_sorted = np.argsort(pred.numpy().flatten())[::-1]\n",
        "    loss = pred[0][class_idxs_sorted[0]]\n",
        "    \n",
        "grads = tape.gradient(loss, images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2C5QF5jTKS-B"
      },
      "outputs": [],
      "source": [
        "dgrad_abs = tf.math.abs(grads)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bxfSjrizKVYu"
      },
      "outputs": [],
      "source": [
        "dgrad_max_ = np.max(dgrad_abs, axis=3)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pbxTmNghKamh"
      },
      "outputs": [],
      "source": [
        "arr_min, arr_max  = np.min(dgrad_max_), np.max(dgrad_max_)\n",
        "grad_eval = (dgrad_max_ - arr_min) / (arr_max - arr_min + 1e-18)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WRN3zrasKdhO"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(1,2,figsize=(14,5))\n",
        "axes[0].imshow(_img)\n",
        "i = axes[1].imshow(grad_eval,cmap=\"jet\",alpha=0.8)\n",
        "fig.colorbar(i)\n",
        "print(np.argmax(pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Removing light"
      ],
      "metadata": {
        "id": "WI0vQcnm--Yw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_2YaUIYe4DTm"
      },
      "outputs": [],
      "source": [
        "image_native = cv2.imread('data/raw_2/3/image_1.jpg')\n",
        "\n",
        "image = cv2.cvtColor(image_native, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "increase = 1\n",
        "\n",
        "v = image[:, :, 2]\n",
        "\n",
        "v = np.where(v < 170, v + increase, 170)\n",
        "\n",
        "image[:, :, 2] = v\n",
        "\n",
        "image = cv2.cvtColor(image, cv2.COLOR_HSV2BGR)\n",
        "\n",
        "cv2_imshow(image_native)\n",
        "cv2_imshow(image)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "authorship_tag": "ABX9TyME82IYvdcNSH4p+K9bOFLI",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}